{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.environ[\"HOME\"] + '/tmp_projects/reproduction-soft-qlearning-mutual-information')\n",
    "sys.path.append(os.environ[\"HOME\"] + '/tmp_projects/reproduction-soft-qlearning-mutual-information/tabular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.environ[\"HOME\"] + '/tmp_projects/reproduction-soft-qlearning-mutual-information'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular.agent import RandomAgent, QLAgent, SQLAgent, MIRLAgent, SQL_mAgent\n",
    "from tabular.environment import GridWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular.main import eval_snapshot, plot_results, plot_correct_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import frozendict\n",
    "import random\n",
    "import os\n",
    "from pprint import pprint\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world1 = {\n",
    "    'size': (3, 20),\n",
    "    'reward': (1, 18),\n",
    "    'walls': []\n",
    "}\n",
    "\n",
    "world2 = {\n",
    "    'size': (8, 8),\n",
    "    'reward': (3, 5),\n",
    "    'walls': [(2, 4), (2, 5), (3, 4), (4, 4), (4, 5)]\n",
    "}\n",
    "\n",
    "config = frozendict.frozendict({\n",
    "    'eps_train': 0.1,\n",
    "    'eps_eval': 0.05,\n",
    "    'gamma': 0.999,\n",
    "    'rho_lr': 2e-3,\n",
    "    'beta_lr': 2e-3,   # use?\n",
    "    'c': 1e-3,\n",
    "    'omega': 0.8,\n",
    "    'max_steps': 10000\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimpleNamespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation_data will store info for plot 1\n",
    "evaluation_data = defaultdict(dict)\n",
    "training_data = defaultdict(dict)\n",
    "\n",
    "envs = {\n",
    "    'Grid_World_3x20': world1,\n",
    "    'Grid_World_8x8': world2\n",
    "}\n",
    "# agents = (SQL_mAgent, QLAgent, SQLAgent, MIRLAgent)\n",
    "agents = (MIRLAgent,)\n",
    "\n",
    "# storing info for plot 2\n",
    "correct_info = defaultdict(dict)\n",
    "\n",
    "exp_name = '10k_sqlm'\n",
    "\n",
    "log_folder = ROOT_DIR + '/tabular/logs/%s_%s' % (datetime.datetime.now().strftime('%Y%m%d_%H%M%S'), exp_name)\n",
    "log_step = 1000\n",
    "\n",
    "for envname, envconf in envs.items():\n",
    "    env = GridWorld(envconf)\n",
    "        \n",
    "    for agent_class in agents:\n",
    "        log_subfolder = os.path.join(log_folder, envname.replace(' ', '_'), agent_class.__name__)\n",
    "        os.makedirs(log_subfolder)\n",
    "        \n",
    "        with open(os.path.join(log_subfolder, 'logs.csv'), 'w+') as f_log:\n",
    "            print('\\nTraining agent %s' % agent_class.__name__)\n",
    "            agent = agent_class(env.get_actions(), config)\n",
    "\n",
    "            total_reward = 0\n",
    "            obs = env.reset()\n",
    "            evals = dict()\n",
    "            train = dict()\n",
    "            correct_action = list()\n",
    "\n",
    "            for global_step in range(config.max_steps):\n",
    "                action = agent.choose_action(obs)\n",
    "                reward, next_obs, done = env.action(action)\n",
    "\n",
    "                agent.update(obs, action, reward, next_obs, done)\n",
    "\n",
    "                if (global_step + 1) % 100 == 0:\n",
    "                    eval_reward = eval_snapshot(agent_class, agent.get_checkpoint(), envconf, config)\n",
    "                    evals[global_step] = eval_reward\n",
    "                    print('Step %s, reward eval %s' % (global_step + 1, eval_reward))\n",
    "\n",
    "                if (global_step + 1) % log_step == 0:\n",
    "                    agent.log(log_subfolder, global_step)\n",
    "                    log_vars = ','.join([str(global_step), str(eval_reward)] + agent.get_current_vars()) + '\\n'\n",
    "                    f_log.write(log_vars)\n",
    "                    \n",
    "                # correct action information (different evaluation for both gridworlds)\n",
    "                if envname == 'Grid_World_3x20':        # log correct action at each step\n",
    "                    correct_action.append(1 if action == 1 else 0)\n",
    "                elif envname == 'Grid_World_8x8':       # log correct action at state (3,6)\n",
    "                    x_agent, y_agent = np.where(obs == 3)\n",
    "                    if (x_agent[0], y_agent[0]) == (3, 6):\n",
    "                        correct_action.append(1 if action == 3 else 0)\n",
    "                    \n",
    "                total_reward += reward\n",
    "                obs = next_obs\n",
    "                # env.display()\n",
    "                \n",
    "                if done:\n",
    "                    # print(\"Env done with reward %s\" % total_reward)\n",
    "                    train[global_step] = total_reward\n",
    "                    total_reward = 0\n",
    "                    obs = env.reset()\n",
    "\n",
    "        evaluation_data[envname][agent_class.__name__] = evals\n",
    "        training_data[envname][agent_class.__name__] = train\n",
    "        correct_info[envname][agent_class.__name__] = correct_action\n",
    "            \n",
    "        with open(os.path.join(log_subfolder, 'eval_data.json'), 'w+') as f_dump:\n",
    "            f_dump.write(json.dumps(evals))\n",
    "        \n",
    "        with open(os.path.join(log_subfolder, 'correct_action.json'), 'w+') as f_correct:\n",
    "            f_correct.write(json.dumps({'data': correct_action}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_colors = {\n",
    "    'QLAgent': 'g',\n",
    "    'SQLAgent': 'orangered',\n",
    "    'SQL_mAgent': 'orange',\n",
    "    'MIRLAgent': 'royalblue',\n",
    "    'MIRL_oldAgent': 'purple'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(evaluation_data, log_folder, alpha_agents=None):\n",
    "    for envname, env_eval_data in evaluation_data.items():\n",
    "        for agent_type, eval_data in env_eval_data.items():\n",
    "            data_x = np.array(list(eval_data.keys()))\n",
    "            data_y = np.array(list(eval_data.values()))\n",
    "            x_smooth = np.linspace(data_x.min(), data_x.max(), 200)\n",
    "            f_smooth = interp1d(data_x, data_y, kind='cubic')\n",
    "            df = pd.Series(data_y)\n",
    "            \n",
    "            alpha = 0.4 if (alpha_agents and agent_type in alpha_agents) else 1.0\n",
    "            plt.plot(data_x, df.ewm(span=10).mean(), paper_colors[agent_type], label='%s' % agent_type.replace('Agent', ''), alpha=alpha)\n",
    "            # plt.plot(data_x, df.ewm(span=10).mean(), label='%s' % agent_type.replace('Agent', ''), alpha=alpha)\n",
    "\n",
    "        plt.xlabel('environment interactions')\n",
    "        plt.ylabel('reward')\n",
    "        plt.legend()\n",
    "        plt.title(envname)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"logging in log_folder %s\" % log_folder)\n",
    "        \n",
    "        if log_folder:\n",
    "            plt.savefig(log_folder + '/results_%s.png' % envname)\n",
    "            \n",
    "        plt.gcf().clear()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(evaluation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correct action\n",
    "\n",
    "def plot_correct_action(correct_info, log_folder=None, alpha_agents=None):\n",
    "    labels = {\n",
    "        'Grid_World_3x20': {\n",
    "            'title': 'Correct action while training',\n",
    "            'x_label': 'Training step',\n",
    "            'y_label': '1: Correct action (right), 0: Incorrect action'\n",
    "        },\n",
    "        'Grid_World_8x8': {\n",
    "            'title': 'Correct Infrequent action',\n",
    "            'x_label': 'Interactions in state (3, 6)',\n",
    "            'y_label': '1: Correct action (left), 0: Incorrect action'\n",
    "        } \n",
    "    }\n",
    "\n",
    "    for envname, correct_data in correct_info.items():\n",
    "        envname = envname.replace(' ', '_')\n",
    "        for agent_type, correct_action in correct_data.items():\n",
    "            data_x = np.arange(0, len(correct_action), 1)\n",
    "            data_y = np.array(correct_action)\n",
    "            df = pd.Series(correct_action)\n",
    "            \n",
    "            alpha = 0.4 if (alpha_agents and agent_type in alpha_agents) else 1.0\n",
    "            plt.plot(data_x, df.ewm(span=1000).mean(), paper_colors[agent_type], label=agent_type.replace('Agent', ''), alpha=alpha)\n",
    "            # plt.plot(data_x, df.ewm(span=1000).mean(), label=agent_type.replace('Agent', ''), alpha=alpha)\n",
    "\n",
    "        plt.xlabel(labels[envname]['x_label'])\n",
    "        plt.ylabel(labels[envname]['y_label'])\n",
    "        plt.legend()\n",
    "        plt.title(labels[envname]['title'])\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        if log_folder:\n",
    "            plt.savefig(log_folder + '/actions_%s.png' % envname)\n",
    "            \n",
    "        plt.gcf().clear()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correct_action(correct_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# plot existing experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = \"/Users/voltali/tmp_projects/grotile/tabular/logs/20190104_230535_all_10k\"\n",
    "\n",
    "env_names = ['Grid_World_3x20', 'Grid_World_8x8']\n",
    "agent_names = ['QLAgent', 'SQLAgent', 'SQL_mAgent', 'MIRLAgent']\n",
    "\n",
    "eval_data = defaultdict(dict)\n",
    "correct_data = defaultdict(dict)\n",
    "\n",
    "for envname in env_names:\n",
    "    for agentname in agent_names:\n",
    "        data_path = os.path.join(experiment_dir, envname, agentname, 'eval_data.json')\n",
    "        with open(data_path, 'r') as f_eval:\n",
    "            data = json.loads(f_eval.read())\n",
    "            eval_data[envname][agentname] = {int(k): v for k, v in data.items()}\n",
    "            \n",
    "        correct_action_path = os.path.join(experiment_dir, envname, agentname, 'correct_action.json')\n",
    "        with open(correct_action_path, 'r') as f_correct:\n",
    "            data = json.loads(f_correct.read())\n",
    "            correct_data[envname][agentname] = data['data']\n",
    "            \n",
    "plot_results(eval_data)\n",
    "plot_correct_action(correct_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot experiments from different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple(paths, alpha_agents=None):\n",
    "    eval_data = defaultdict(dict)\n",
    "    correct_data = defaultdict(dict)\n",
    "\n",
    "    savedir = ROOT_DIR + \"/tabular/logs/results/performance\"\n",
    "\n",
    "    for envname, data in paths.items():\n",
    "        for agentname, basedir in data.items():\n",
    "            path_agent = \"MIRLAgent\" if agentname == \"MIRL_oldAgent\" else agentname  # ...\n",
    "            data_path = os.path.join(basedir, envname, path_agent, 'eval_data.json')\n",
    "            with open(data_path, 'r') as f_eval:\n",
    "                data = json.loads(f_eval.read())\n",
    "                eval_data[envname][agentname] = {int(k): v for k, v in data.items()}\n",
    "\n",
    "            correct_action_path = os.path.join(basedir, envname, path_agent, 'correct_action.json')\n",
    "            with open(correct_action_path, 'r') as f_correct:\n",
    "                data = json.loads(f_correct.read())\n",
    "                correct_data[envname][agentname] = data['data']\n",
    "\n",
    "    print(\"hello\")\n",
    "    plot_results(eval_data, log_folder=savedir, alpha_agents=alpha_agents)\n",
    "    plot_correct_action(correct_data, log_folder=savedir, alpha_agents=alpha_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100k results\n",
    "\n",
    "# 100k MIRL on 3x20 and 8x8 (old)\n",
    "mirl = \"/Users/voltali/tmp_projects/grotile/tabular/logs/results/20190104_203749_100k_mirl\"\n",
    "\n",
    "# 100k all on 8x8\n",
    "all_8x8 = \"/Users/voltali/tmp_projects/grotile/tabular/logs/results/20190106_161824_100k_all_8x8\"\n",
    "\n",
    "# 100k all on 3x20\n",
    "all_3x20 = \"/Users/voltali/tmp_projects/grotile/tabular/logs/results/20190105_020922_all_100k\"\n",
    "\n",
    "paths_100k = {\n",
    "    'Grid_World_3x20': {\n",
    "        'QLAgent': all_3x20,\n",
    "        'SQLAgent': all_3x20,\n",
    "        'SQL_mAgent': all_3x20,\n",
    "        'MIRLAgent': mirl\n",
    "    },\n",
    "    'Grid_World_8x8': {\n",
    "        'QLAgent': all_8x8,\n",
    "        'SQLAgent': all_8x8,\n",
    "        'SQL_mAgent': all_8x8,\n",
    "        'MIRLAgent': mirl\n",
    "    }\n",
    "}\n",
    "\n",
    "plot_multiple(paths_100k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10k performance experiments\n",
    "\n",
    "all_10k = ROOT_DIR + \"/tabular/logs/20190104_230535_all_10k\"\n",
    "mirl_10k_gamma0999_lr2e3 = ROOT_DIR + \"/tabular/logs/20190107_151231_10k_sqlm\"\n",
    "mirl_10k_gamma0999_lr1e3 = ROOT_DIR + \"/tabular/logs/20190107_152451_10k_mirl_0999_1e-3\"\n",
    "mirl_10k_gamma0999_lr2e4 = ROOT_DIR + \"/tabular/logs/20190107_155600_10k_mirl_0999_2e-4\"\n",
    "mirl_10k_gamma0999_lr1e4 = ROOT_DIR + \"/tabular/logs/20190107_161735_10k_mirl_0999_1e-4\"\n",
    "mirl_10k_gamma0999_lr5e4 = ROOT_DIR + \"/tabular/logs/20190107_164623_10k_mirl_0999_5e-4\"\n",
    "\n",
    "new_10k = ROOT_DIR + \"/tabular/logs/20190107_172656_10k_others_0999_2e-4\"\n",
    "\n",
    "paths_10k = {\n",
    "    'Grid_World_3x20': {\n",
    "        'QLAgent': new_10k,\n",
    "        'SQLAgent': new_10k,\n",
    "        'SQL_mAgent': new_10k,\n",
    "        'MIRLAgent': mirl_10k_gamma0999_lr2e4\n",
    "    },\n",
    "    'Grid_World_8x8': {\n",
    "        'QLAgent': new_10k,\n",
    "        'SQLAgent': new_10k,\n",
    "        'SQL_mAgent': new_10k,\n",
    "        'MIRLAgent': mirl_10k_gamma0999_lr2e4\n",
    "    }\n",
    "}\n",
    "plot_multiple(paths_10k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot different experiments of MIRL\n",
    "paths_10k = {\n",
    "    'gamma = 0.99; alpha_rho = 2e-3': all_10k,\n",
    "    'gamma = 0.999; alpha_rho = 2e-3': mirl_10k_gamma0999_lr2e3,\n",
    "    'gamma = 0.999; alpha_rho = 1e-3': mirl_10k_gamma0999_lr1e3,\n",
    "    'gamma = 0.999; alpha_rho = 2e-4': mirl_10k_gamma0999_lr2e4,\n",
    "    'gamma = 0.999; alpha_rho = 1e-4': mirl_10k_gamma0999_lr1e4,\n",
    "    'gamma = 0.999; alpha_rho = 5e-4': mirl_10k_gamma0999_lr5e4\n",
    "}\n",
    "\n",
    "eval_data = defaultdict(dict)\n",
    "correct_data = defaultdict(dict)\n",
    "\n",
    "savedir = ROOT_DIR + \"/tabular/logs/results/performance\"\n",
    "\n",
    "for envname in [\"Grid_World_3x20\", \"Grid_World_8x8\"]:\n",
    "    for caption, path in paths_10k.items():\n",
    "        data_path = os.path.join(path, envname, 'MIRLAgent', 'eval_data.json')\n",
    "        with open(data_path, 'r') as f_eval:\n",
    "            data = json.loads(f_eval.read())\n",
    "            eval_data[envname][caption] = {int(k): v for k, v in data.items()}\n",
    "\n",
    "        correct_action_path = os.path.join(path, envname, 'MIRLAgent', 'correct_action.json')\n",
    "        with open(correct_action_path, 'r') as f_correct:\n",
    "            data = json.loads(f_correct.read())\n",
    "            correct_data[envname][caption] = data['data']\n",
    "\n",
    "plot_results(eval_data, log_folder=savedir)\n",
    "plot_correct_action(correct_data, log_folder=savedir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiplot for figure 1\n",
    "\n",
    "# column 1 new values\n",
    "# column 2 \n",
    "\n",
    "new_10k = ROOT_DIR + \"/tabular/logs/20190107_172656_10k_others_0999_2e-4\"\n",
    "comparison = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
